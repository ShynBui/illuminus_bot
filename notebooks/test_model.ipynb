{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b833b7b-b650-4007-99cd-d196087c78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.path.dirname(os.getcwd()), 'models', 'checkpoint-36')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489bf4f1-a744-4ae8-bbd5-39a8b3d8fc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4f341189924b3b916c498b784eb65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tải model và tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(output_dir).to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7b81fc-6970-4ce4-be41-39d883ccf6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_files(train_json_path, test_json_path):\n",
    "    \"\"\"\n",
    "    Hàm nhận vào đường dẫn đến các tệp JSON chứa train và test, sau đó tạo DatasetDict\n",
    "    theo cấu trúc messages với role \"system\", \"user\", và \"assistant\".\n",
    "    \n",
    "    Args:\n",
    "        train_json_path (str): Đường dẫn đến tệp JSON chứa dữ liệu huấn luyện.\n",
    "        test_json_path (str): Đường dẫn đến tệp JSON chứa dữ liệu kiểm tra.\n",
    "        \n",
    "    Returns:\n",
    "        DatasetDict: Bao gồm tập train và test dưới dạng Hugging Face Dataset.\n",
    "    \"\"\"\n",
    "    # Bước 1: Đọc tệp JSON train và test\n",
    "    with open(train_json_path, 'r', encoding='utf-8') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    with open(test_json_path, 'r', encoding='utf-8') as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    # Khởi tạo danh sách train_data và test_data để lưu cặp input-output\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "\n",
    "    # Bước 2: Tiền xử lý và tách các đoạn hội thoại thành các cặp input-output cho tập train\n",
    "    for item in train_data:\n",
    "        previous_context = item[\"previous_context\"]\n",
    "        topic = item[\"topic\"]\n",
    "        language = item[\"language\"]\n",
    "        conversation = item[\"conversation\"]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            if conversation[i][\"speaker\"] == \"David\" and conversation[i + 1][\"speaker\"] == \"Choi\":\n",
    "                # Input: Tạo đoạn hội thoại phù hợp với \"user\"\n",
    "                input_message = (f\"Previous context: {previous_context}\\n\"\n",
    "                                 f\"Topic: {topic}\\n\"\n",
    "                                 f\"Language: {language}\\n\"\n",
    "                                 f\"David's Emotion: {conversation[i]['emotion']}\\n\"\n",
    "                                 f\"Choi's Role: {conversation[i+1]['role']}\\n\"\n",
    "                                 f\"Choi's Emotion: {conversation[i+1]['emotion']}\\n\")\n",
    "\n",
    "                # Output: Cả hội thoại giữa David và Choi\n",
    "                output_message = (f\"David's Text: {conversation[i]['text']}\\n\"\n",
    "                                  f\"Choi's Text: {conversation[i+1]['text']}\")\n",
    "\n",
    "                # Tạo cấu trúc messages\n",
    "                conversation_messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\"},\n",
    "                    {\"role\": \"user\", \"content\": input_message},\n",
    "                    {\"role\": \"assistant\", \"content\": output_message}\n",
    "                ]\n",
    "\n",
    "                # Thêm cặp input-output vào train_data\n",
    "                train_samples.append({\n",
    "                    \"messages\": conversation_messages\n",
    "                })\n",
    "\n",
    "    # Tương tự cho tập test\n",
    "    for item in test_data:\n",
    "        previous_context = item[\"previous_context\"]\n",
    "        topic = item[\"topic\"]\n",
    "        language = item[\"language\"]\n",
    "        conversation = item[\"conversation\"]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            if conversation[i][\"speaker\"] == \"David\" and conversation[i + 1][\"speaker\"] == \"Choi\":\n",
    "                # Input: Tạo đoạn hội thoại phù hợp với \"user\"\n",
    "                input_message = (f\"Previous context: {previous_context}\\n\"\n",
    "                                 f\"Topic: {topic}\\n\"\n",
    "                                 f\"Language: {language}\\n\"\n",
    "                                 f\"David's Emotion: {conversation[i]['emotion']}\\n\"\n",
    "                                 f\"Choi's Role: {conversation[i+1]['role']}\\n\"\n",
    "                                 f\"Choi's Emotion: {conversation[i+1]['emotion']}\\n\")\n",
    "\n",
    "                # Output: Cả hội thoại giữa David và Choi\n",
    "                output_message = (f\"David's Text: {conversation[i]['text']}\\n\"\n",
    "                                  f\"Choi's Text: {conversation[i+1]['text']}\")\n",
    "\n",
    "                # Tạo cấu trúc messages\n",
    "                conversation_messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\"},\n",
    "                    {\"role\": \"user\", \"content\": input_message},\n",
    "                    {\"role\": \"assistant\", \"content\": output_message}\n",
    "                ]\n",
    "\n",
    "                # Thêm cặp input-output vào test_data\n",
    "                test_samples.append({\n",
    "                    \"messages\": conversation_messages\n",
    "                })\n",
    "\n",
    "    # Bước 3: Tạo Dataset cho train và test bằng DatasetDict\n",
    "    dataset_dict = DatasetDict({\n",
    "        \"train\": Dataset.from_list(train_samples),\n",
    "        \"test\": Dataset.from_list(test_samples)\n",
    "    })\n",
    "\n",
    "    return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6bd960-919f-4df3-ba15-c68531bd86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (os.path.join(os.path.dirname(os.getcwd()), 'data', 'train_data.json'))\n",
    "test_path = (os.path.join(os.path.dirname(os.getcwd()), 'data', 'test_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c5347a-6ff3-4bfe-b76d-bc5f3371cb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_dataset_from_files(data_path, test_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d82d0a-4fd5-44f6-83a1-2939eae33d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYour task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.<|im_end|>\\n<|im_start|>user\\nPrevious context: David was reminiscing about his time in the U.S., laughing about a funny incident with his colleagues. Choi was enjoying his father's lighthearted mood.\\nTopic: David's current health\\nLanguage: Korean\\nDavid's Emotion: humorous\\nChoi's Role: Humorous storyteller\\nChoi's Emotion: comforting\\n<|im_end|>\\n<|im_start|>assistant\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = text = tokenizer.apply_chat_template(\n",
    "    dataset['train']['messages'][4],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "test_text = '\\n'.join(test_text.split(\"\\n\")[:-4]) + '\\n'\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1ea78bc-968d-4073-946c-cea6729cac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_test_text = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14cb9de6-72f2-4dea-915b-e89dc41ddac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   7771,   3383,    374,    311,   6923,    264,\n",
       "          10435,   1948,   6798,    323,  86573,     13,   6798,    686,   2548,\n",
       "           4755,    476,   3061,   3118,    389,    806,  21261,    323,   2266,\n",
       "             11,    323,  86573,    686,   5889,  34901,   4092,    311,    806,\n",
       "           3476,    323,  19772,     13, 151645,    198, 151644,    872,    198,\n",
       "          21291,   2266,     25,   6798,    572,  42550,  52754,    911,    806,\n",
       "            882,    304,    279,    547,    808,   2572,  31581,    911,    264,\n",
       "          15173,  10455,    448,    806,  17639,     13,  86573,    572,  21413,\n",
       "            806,   6981,    594,    326,   1090,   1782,    471,    291,  19671,\n",
       "            624,  26406,     25,   6798,    594,   1482,   2820,    198,  13806,\n",
       "             25,  16134,    198,  22286,    594,   5748,   5956,     25,  69846,\n",
       "            198,   1143,   6728,    594,  15404,     25,  19858,  20244,  40006,\n",
       "           7073,    198,   1143,   6728,    594,   5748,   5956,     25,  68030,\n",
       "            198, 151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_test_text.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea4b04cd-23af-40a8-a9c1-0076a3ded760",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**tokenizer_test_text, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30fc9425-515a-4c36-a9e8-0208bdd6415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: system\n",
      "Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\n",
      "user\n",
      "Previous context: David was reminiscing about his time in the U.S., laughing about a funny incident with his colleagues. Choi was enjoying his father's lighthearted mood.\n",
      "Topic: David's current health\n",
      "Language: Korean\n",
      "David's Emotion: humorous\n",
      "Choi's Role: Humorous storyteller\n",
      "Choi's Emotion: comforting\n",
      "\n",
      "assistant\n",
      "David: \"아이고, 내가 한국에서 농담을 들었을 때는 정말로 놀랐어. 그 사람이 말하는 대로 따라 했는데, 그 농담이 너무 웃겼어. \"\n",
      "Choi: \"그런 일이 있나요? 제가 아버님을 웃게 하려고 해야겠네요.\"\n",
      "David: \"그래, 그때는 정말로 웃었어. 그 농담은 '당신이 죽으면 당신의 친구들이 당신의 배를 빨아들여야 합니다'라는 거야. 그게 완전히 웃기다. \"\n",
      "Choi: \"저도 아버님의 이야기가 웃겨요. 저도 아버님의 농담에 웃었습니다. 아버님의 농담이 웃긴 이유는 그 농담이 현실적으로 웃기기 때문이에요. 그리고 저는 항상 아버님의 웃음을 기원합니다.\"\n"
     ]
    }
   ],
   "source": [
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Output:\", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735dd1a2-740c-456e-8a7d-bd998ae50091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
