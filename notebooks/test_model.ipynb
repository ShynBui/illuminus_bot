{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b833b7b-b650-4007-99cd-d196087c78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.path.dirname(os.getcwd()), 'models', 'checkpoint-150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489bf4f1-a744-4ae8-bbd5-39a8b3d8fc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d6470312294da59e8af44434e3479b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tải model và tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(output_dir).to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d7b81fc-6970-4ce4-be41-39d883ccf6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_files(train_json_path, test_json_path):\n",
    "    \"\"\"\n",
    "    Hàm nhận vào đường dẫn đến các tệp JSON chứa train và test, sau đó tạo DatasetDict\n",
    "    theo cấu trúc messages với role \"system\", \"user\", và \"assistant\".\n",
    "    \n",
    "    Args:\n",
    "        train_json_path (str): Đường dẫn đến tệp JSON chứa dữ liệu huấn luyện.\n",
    "        test_json_path (str): Đường dẫn đến tệp JSON chứa dữ liệu kiểm tra.\n",
    "        \n",
    "    Returns:\n",
    "        DatasetDict: Bao gồm tập train và test dưới dạng Hugging Face Dataset.\n",
    "    \"\"\"\n",
    "    # Bước 1: Đọc tệp JSON train và test\n",
    "    with open(train_json_path, 'r', encoding='utf-8') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    with open(test_json_path, 'r', encoding='utf-8') as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    # Khởi tạo danh sách train_data và test_data để lưu cặp input-output\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "\n",
    "    # Bước 2: Tiền xử lý và tách các đoạn hội thoại thành các cặp input-output cho tập train\n",
    "    for item in train_data:\n",
    "        previous_context = item[\"previous_context\"]\n",
    "        topic = item[\"topic\"]\n",
    "        language = item[\"language\"]\n",
    "        conversation = item[\"conversation\"]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            if conversation[i][\"speaker\"] == \"David\" and conversation[i + 1][\"speaker\"] == \"Choi\":\n",
    "                # Input: Tạo đoạn hội thoại phù hợp với \"user\"\n",
    "                input_message = (f\"Previous context: {previous_context}\\n\"\n",
    "                                 f\"Topic: {topic}\\n\"\n",
    "                                 f\"Language: {language}\\n\"\n",
    "                                 f\"David's Emotion: {conversation[i]['emotion']}\\n\"\n",
    "                                 f\"Choi's Role: {conversation[i+1]['role']}\\n\"\n",
    "                                 f\"Choi's Emotion: {conversation[i+1]['emotion']}\\n\")\n",
    "\n",
    "                # Output: Cả hội thoại giữa David và Choi\n",
    "                output_message = (f\"David's Text: {conversation[i]['text']}\\n\"\n",
    "                                  f\"Choi's Text: {conversation[i+1]['text']}\")\n",
    "\n",
    "                # Tạo cấu trúc messages\n",
    "                conversation_messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\"},\n",
    "                    {\"role\": \"user\", \"content\": input_message},\n",
    "                    {\"role\": \"assistant\", \"content\": output_message}\n",
    "                ]\n",
    "\n",
    "                # Thêm cặp input-output vào train_data\n",
    "                train_samples.append({\n",
    "                    \"messages\": conversation_messages\n",
    "                })\n",
    "\n",
    "    # Tương tự cho tập test\n",
    "    for item in test_data:\n",
    "        previous_context = item[\"previous_context\"]\n",
    "        topic = item[\"topic\"]\n",
    "        language = item[\"language\"]\n",
    "        conversation = item[\"conversation\"]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            if conversation[i][\"speaker\"] == \"David\" and conversation[i + 1][\"speaker\"] == \"Choi\":\n",
    "                # Input: Tạo đoạn hội thoại phù hợp với \"user\"\n",
    "                input_message = (f\"Previous context: {previous_context}\\n\"\n",
    "                                 f\"Topic: {topic}\\n\"\n",
    "                                 f\"Language: {language}\\n\"\n",
    "                                 f\"David's Emotion: {conversation[i]['emotion']}\\n\"\n",
    "                                 f\"Choi's Role: {conversation[i+1]['role']}\\n\"\n",
    "                                 f\"Choi's Emotion: {conversation[i+1]['emotion']}\\n\")\n",
    "\n",
    "                # Output: Cả hội thoại giữa David và Choi\n",
    "                output_message = (f\"David's Text: {conversation[i]['text']}\\n\"\n",
    "                                  f\"Choi's Text: {conversation[i+1]['text']}\")\n",
    "\n",
    "                # Tạo cấu trúc messages\n",
    "                conversation_messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\"},\n",
    "                    {\"role\": \"user\", \"content\": input_message},\n",
    "                    {\"role\": \"assistant\", \"content\": output_message}\n",
    "                ]\n",
    "\n",
    "                # Thêm cặp input-output vào test_data\n",
    "                test_samples.append({\n",
    "                    \"messages\": conversation_messages\n",
    "                })\n",
    "\n",
    "    # Bước 3: Tạo Dataset cho train và test bằng DatasetDict\n",
    "    dataset_dict = DatasetDict({\n",
    "        \"train\": Dataset.from_list(train_samples),\n",
    "        \"test\": Dataset.from_list(test_samples)\n",
    "    })\n",
    "\n",
    "    return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be6bd960-919f-4df3-ba15-c68531bd86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (os.path.join(os.path.dirname(os.getcwd()), 'data', 'train_data.json'))\n",
    "test_path = (os.path.join(os.path.dirname(os.getcwd()), 'data', 'test_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c5347a-6ff3-4bfe-b76d-bc5f3371cb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_dataset_from_files(data_path, test_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b142f9fd-a5dd-41c8-852e-af1b7fcb5bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.',\n",
       "  'role': 'system'},\n",
       " {'content': \"Previous context: David was confused about his role at his old job in the U.S. Choi was reminding him about the time he managed a successful project there.\\nTopic: David's old job in the U.S.\\nLanguage: Mixed English-Korean\\nDavid's Emotion: humorous\\nChoi's Role: Son\\nChoi's Emotion: patient\\n\",\n",
       "  'role': 'user'},\n",
       " {'content': \"David's Text: Ah, that job! I was the big boss, right?  I think I even had a fancy office with a view.  Maybe I was even the CEO?  Or was that just in my dreams?\\nChoi's Text: You were a manager, Dad.  You were in charge of a big team, and you did a great job.  Remember that project you led?  The one with the… what was it called again?  The…  Ah, the ‘Blue Sky’ project!  You were the one who came up with the idea, remember?\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['messages'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d82d0a-4fd5-44f6-83a1-2939eae33d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYour task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.<|im_end|>\\n<|im_start|>user\\nPrevious context: David was confused about his role at his old job in the U.S. Choi was reminding him about the time he managed a successful project there.\\nTopic: David's old job in the U.S.\\nLanguage: Mixed English-Korean\\nDavid's Emotion: humorous\\nChoi's Role: Son\\nChoi's Emotion: patient\\n<|im_end|>\\n<|im_start|>assistant\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = text = tokenizer.apply_chat_template(\n",
    "    dataset['train']['messages'][0],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "test_text = '\\n'.join(test_text.split(\"\\n\")[:-4]) + '\\n'\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1ea78bc-968d-4073-946c-cea6729cac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_test_text = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14cb9de6-72f2-4dea-915b-e89dc41ddac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   7771,   3383,    374,    311,   6923,    264,\n",
       "          10435,   1948,   6798,    323,  86573,     13,   6798,    686,   2548,\n",
       "           4755,    476,   3061,   3118,    389,    806,  21261,    323,   2266,\n",
       "             11,    323,  86573,    686,   5889,  34901,   4092,    311,    806,\n",
       "           3476,    323,  19772,     13, 151645,    198, 151644,    872,    198,\n",
       "          21291,   2266,     25,   6798,    572,  21815,    911,    806,   3476,\n",
       "            518,    806,   2310,   2618,    304,    279,    547,    808,     13,\n",
       "          86573,    572,  62942,   1435,    911,    279,    882,    566,   8975,\n",
       "            264,   6849,   2390,   1052,    624,  26406,     25,   6798,    594,\n",
       "           2310,   2618,    304,    279,    547,    808,    624,  13806,     25,\n",
       "          50168,   6364,  15843,  45195,    198,  22286,    594,   5748,   5956,\n",
       "             25,  69846,    198,   1143,   6728,    594,  15404,     25,  11840,\n",
       "            198,   1143,   6728,    594,   5748,   5956,     25,   8720,    198,\n",
       "         151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_test_text.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea4b04cd-23af-40a8-a9c1-0076a3ded760",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**tokenizer_test_text, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30fc9425-515a-4c36-a9e8-0208bdd6415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: system\n",
      "Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\n",
      "user\n",
      "Previous context: David was confused about his role at his old job in the U.S. Choi was reminding him about the time he managed a successful project there.\n",
      "Topic: David's old job in the U.S.\n",
      "Language: Mixed English-Korean\n",
      "David's Emotion: humorous\n",
      "Choi's Role: Son\n",
      "Choi's Emotion: patient\n",
      "\n",
      "assistant\n",
      "David's Text: Oh yeah, I remember that project! We were like, 'We can do this! We can make it happen!' But then, we hit a wall with those pesky regulations. It was like trying to build a house with all these weird rules, you know? It was a real mess!\n",
      "Choi's Text: Yeah, Dad, those regulations were definitely a challenge. But you handled them so well. Remember how you convinced everyone to use those new software tools to streamline everything? That saved us a lot of time and headaches.\n",
      "David's Text: Oh, that reminds me! I was so proud of myself for finally getting that software installed. It was like, 'Finally, we're going to be able to do things more efficiently!' But then, it turned out to be a nightmare. It kept crashing and causing all sorts of problems.\n",
      "Choi's Text: Yeah, I remember that. You were always so enthusiastic about new technologies, but sometimes they just don't work out as planned. But you learned from your mistakes, and eventually, you found a solution that worked.\n"
     ]
    }
   ],
   "source": [
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Output:\", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735dd1a2-740c-456e-8a7d-bd998ae50091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
