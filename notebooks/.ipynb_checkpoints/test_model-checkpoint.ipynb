{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b833b7b-b650-4007-99cd-d196087c78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.path.dirname(os.getcwd()), 'models', 'checkpoint-36')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489bf4f1-a744-4ae8-bbd5-39a8b3d8fc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcd06b3cffc45fda2e0fc5cc0aa0d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tải model và tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(output_dir).to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7b81fc-6970-4ce4-be41-39d883ccf6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_files(train_json_path, test_json_path):\n",
    "    \"\"\"\n",
    "    Hàm nhận vào đường dẫn đến các tệp JSON chứa train và test, sau đó tạo DatasetDict\n",
    "    theo cấu trúc messages với role \"system\", \"user\", và \"assistant\".\n",
    "    \n",
    "    Args:\n",
    "        train_json_path (str): Đường dẫn đến tệp JSON chứa dữ liệu huấn luyện.\n",
    "        test_json_path (str): Đường dẫn đến tệp JSON chứa dữ liệu kiểm tra.\n",
    "        \n",
    "    Returns:\n",
    "        DatasetDict: Bao gồm tập train và test dưới dạng Hugging Face Dataset.\n",
    "    \"\"\"\n",
    "    # Bước 1: Đọc tệp JSON train và test\n",
    "    with open(train_json_path, 'r', encoding='utf-8') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    with open(test_json_path, 'r', encoding='utf-8') as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    # Khởi tạo danh sách train_data và test_data để lưu cặp input-output\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "\n",
    "    # Bước 2: Tiền xử lý và tách các đoạn hội thoại thành các cặp input-output cho tập train\n",
    "    for item in train_data:\n",
    "        previous_context = item[\"previous_context\"]\n",
    "        topic = item[\"topic\"]\n",
    "        language = item[\"language\"]\n",
    "        conversation = item[\"conversation\"]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            if conversation[i][\"speaker\"] == \"David\" and conversation[i + 1][\"speaker\"] == \"Choi\":\n",
    "                # Input: Tạo đoạn hội thoại phù hợp với \"user\"\n",
    "                input_message = (f\"Previous context: {previous_context}\\n\"\n",
    "                                 f\"Topic: {topic}\\n\"\n",
    "                                 f\"Language: {language}\\n\"\n",
    "                                 f\"David's Emotion: {conversation[i]['emotion']}\\n\"\n",
    "                                 f\"Choi's Role: {conversation[i+1]['role']}\\n\"\n",
    "                                 f\"Choi's Emotion: {conversation[i+1]['emotion']}\\n\")\n",
    "\n",
    "                # Output: Cả hội thoại giữa David và Choi\n",
    "                output_message = (f\"David's Text: {conversation[i]['text']}\\n\"\n",
    "                                  f\"Choi's Text: {conversation[i+1]['text']}\")\n",
    "\n",
    "                # Tạo cấu trúc messages\n",
    "                conversation_messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\"},\n",
    "                    {\"role\": \"user\", \"content\": input_message},\n",
    "                    {\"role\": \"assistant\", \"content\": output_message}\n",
    "                ]\n",
    "\n",
    "                # Thêm cặp input-output vào train_data\n",
    "                train_samples.append({\n",
    "                    \"messages\": conversation_messages\n",
    "                })\n",
    "\n",
    "    # Tương tự cho tập test\n",
    "    for item in test_data:\n",
    "        previous_context = item[\"previous_context\"]\n",
    "        topic = item[\"topic\"]\n",
    "        language = item[\"language\"]\n",
    "        conversation = item[\"conversation\"]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            if conversation[i][\"speaker\"] == \"David\" and conversation[i + 1][\"speaker\"] == \"Choi\":\n",
    "                # Input: Tạo đoạn hội thoại phù hợp với \"user\"\n",
    "                input_message = (f\"Previous context: {previous_context}\\n\"\n",
    "                                 f\"Topic: {topic}\\n\"\n",
    "                                 f\"Language: {language}\\n\"\n",
    "                                 f\"David's Emotion: {conversation[i]['emotion']}\\n\"\n",
    "                                 f\"Choi's Role: {conversation[i+1]['role']}\\n\"\n",
    "                                 f\"Choi's Emotion: {conversation[i+1]['emotion']}\\n\")\n",
    "\n",
    "                # Output: Cả hội thoại giữa David và Choi\n",
    "                output_message = (f\"David's Text: {conversation[i]['text']}\\n\"\n",
    "                                  f\"Choi's Text: {conversation[i+1]['text']}\")\n",
    "\n",
    "                # Tạo cấu trúc messages\n",
    "                conversation_messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\"},\n",
    "                    {\"role\": \"user\", \"content\": input_message},\n",
    "                    {\"role\": \"assistant\", \"content\": output_message}\n",
    "                ]\n",
    "\n",
    "                # Thêm cặp input-output vào test_data\n",
    "                test_samples.append({\n",
    "                    \"messages\": conversation_messages\n",
    "                })\n",
    "\n",
    "    # Bước 3: Tạo Dataset cho train và test bằng DatasetDict\n",
    "    dataset_dict = DatasetDict({\n",
    "        \"train\": Dataset.from_list(train_samples),\n",
    "        \"test\": Dataset.from_list(test_samples)\n",
    "    })\n",
    "\n",
    "    return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6bd960-919f-4df3-ba15-c68531bd86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (os.path.join(os.path.dirname(os.getcwd()), 'data', 'train_data.json'))\n",
    "test_path = (os.path.join(os.path.dirname(os.getcwd()), 'data', 'test_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c5347a-6ff3-4bfe-b76d-bc5f3371cb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_dataset_from_files(data_path, test_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7d82d0a-4fd5-44f6-83a1-2939eae33d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYour task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.<|im_end|>\\n<|im_start|>user\\nPrevious context: David was confused about his role at his old job in the U.S. Choi was reminding him about the time he managed a successful project there.\\nTopic: David's old job in the U.S.\\nLanguage: Mixed English-Korean\\nDavid's Emotion: humorous\\nChoi's Role: Son\\nChoi's Emotion: patient\\n<|im_end|>\\n<|im_start|>assistant\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = text = tokenizer.apply_chat_template(\n",
    "    dataset['train']['messages'][0],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "test_text = '\\n'.join(test_text.split(\"\\n\")[:-4]) + '\\n'\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1ea78bc-968d-4073-946c-cea6729cac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_test_text = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14cb9de6-72f2-4dea-915b-e89dc41ddac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   7771,   3383,    374,    311,   6923,    264,\n",
       "          10435,   1948,   6798,    323,  86573,     13,   6798,    686,   2548,\n",
       "           4755,    476,   3061,   3118,    389,    806,  21261,    323,   2266,\n",
       "             11,    323,  86573,    686,   5889,  34901,   4092,    311,    806,\n",
       "           3476,    323,  19772,     13, 151645,    198, 151644,    872,    198,\n",
       "          21291,   2266,     25,   6798,    572,  21815,    911,    806,   3476,\n",
       "            518,    806,   2310,   2618,    304,    279,    547,    808,     13,\n",
       "          86573,    572,  62942,   1435,    911,    279,    882,    566,   8975,\n",
       "            264,   6849,   2390,   1052,    624,  26406,     25,   6798,    594,\n",
       "           2310,   2618,    304,    279,    547,    808,    624,  13806,     25,\n",
       "          50168,   6364,  15843,  45195,    198,  22286,    594,   5748,   5956,\n",
       "             25,  69846,    198,   1143,   6728,    594,  15404,     25,  11840,\n",
       "            198,   1143,   6728,    594,   5748,   5956,     25,   8720,    198,\n",
       "         151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_test_text.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea4b04cd-23af-40a8-a9c1-0076a3ded760",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**tokenizer_test_text, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30fc9425-515a-4c36-a9e8-0208bdd6415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: system\n",
      "Your task is to generate a conversation between David and Choi. David will ask questions or talk based on his emotions and context, and Choi will respond appropriately according to his role and emotion.\n",
      "user\n",
      "Previous context: David was confused about his role at his old job in the U.S. Choi was reminding him about the time he managed a successful project there.\n",
      "Topic: David's old job in the U.S.\n",
      "Language: Mixed English-Korean\n",
      "David's Emotion: humorous\n",
      "Choi's Role: Son\n",
      "Choi's Emotion: patient\n",
      "\n",
      "assistant\n",
      "Choi: David, you were so funny when you told me about that project you managed. You were so good at it! How did it go?\n",
      "David: I think you're just saying that because you love me, but yeah, I did pretty well. I was like, \"Okay, this is how we do things here,\" and then I just ran with it.\n",
      "Choi: [laughs] You must have had fun doing that. But you know what? I'm proud of you, and I hope you can do something similar in your new job.\n",
      "David: [smiling] Thanks, Dad. I'll try my best. But for now, let's talk about this trip we're taking soon. I'm really excited to see all the sights in Korea!\n",
      "Choi: [smiling] That sounds great, son. Korea has so much to offer. We can explore some new places and taste different foods.\n",
      "David: Yeah, and maybe even learn some Korean! I haven't been able to speak Korean since I moved here, and I miss being able to communicate with people.\n",
      "Choi: [laughs] Well, you can always practice with me. I'll be happy to help you learn more about our language.\n",
      "David: [smiling] Thanks, Dad. I appreciate it. Let's get back to work, though. I need to prepare for the big presentation tomorrow.\n",
      "Choi: [nodding] Of course, David. Take care of yourself, and don't forget to enjoy your trip.\n"
     ]
    }
   ],
   "source": [
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Output:\", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735dd1a2-740c-456e-8a7d-bd998ae50091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
